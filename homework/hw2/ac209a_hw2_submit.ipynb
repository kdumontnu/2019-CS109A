{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 2  AC 209 : Linear and k-NN Regression\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2019**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, Chris Tanner\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "<div class='theme'> <b>Linear Regression and Confidence Intervals</b> </div>\n",
    "\n",
    "In this part of the homework, you will see how *uncertainty* in the $\\beta$ coefficients can directly impact our ability to make predictions with a linear regression model and how in general we can do inference on the predictors. \n",
    "\n",
    "The data for this supplement are imported for you in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a little review. The linear model assumes:\n",
    "$$ y_i \\sim N(\\beta_0+\\beta_1 x_i,\\sigma^2 )   $$\n",
    "\n",
    "This means, pun intended, that $ \\mu_{y_i} = \\beta_0+\\beta_1 x_i $, which can be estimated with $ \\hat{\\mu}_{y_i} = \\hat{\\beta}_0+\\hat{\\beta}_1 x_i $.\n",
    "\n",
    "And for a new observation not in the data set, once we measure the new predictor value, $x^*$, we can predict its response, $y^*$, from our model as:\n",
    "$$\\hat{y}^* = \\hat{\\mu}_{y_i} + \\hat{\\varepsilon}^* $$\n",
    "\n",
    "Which can be calculated by using the estimate for $\\hat{\\mu}_{y_i}$ and adding on a randomly selected value for $\\hat{\\varepsilon}^*$ from its assumed (and estimated) distribution, $N(0,\\hat{\\sigma}^2)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"data/cleaned_mtcars.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['mpg']].values\n",
    "X = df[['cyl','disp','hp','wt','qsec']]\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 1 [20 pts] </b> </div>\n",
    "\n",
    "**1.1** Fit a simple linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our true mean predictions at various values of `disp` and make a well-labeled plot showing\n",
    " 1. The observed values of `disp` and `mpg`.\n",
    " 2. The estimated regression line.\n",
    " 3. The upper and lower bounds of the 95% confidence interval for the true average (not the observed) `mpg` at any given displacement.\n",
    " \n",
    "**1.2** Why do we have a confidence interval for our true mean prediction values?  Why isn't the mean prediction just a single number?\n",
    "\n",
    "**1.3** Someone asks what mean `mpg` you would predict for a `disp` value of 400. What do you tell them?  Pay attention to the confidence interval (in 1.1) above.\n",
    "\n",
    "**1.4** Why does the 95% confidence interval for the mean predicted `mpg` appear to curve as we move away from the data's center? \n",
    "\n",
    "**1.5** An alternative way to produce the confidence intervals from 1.1 is through the bootstrap though takes some care.  Create 500 bootstrap samples in order to create 500 bootstrapped regression models and store their estimated intercept and slope values.  Use these bootstrapped estimates to build the 95\\% confidence intervals as in 1.1, and recreate the plot from that question with your new bootstrapped confidence intervals.  Compare this new plot to the one from 1.1.\n",
    "\n",
    "**1.6** Another interval of uncertainty in a regression model is called a *prediction interval*.  A prediction interval gives a range of plausible values for a future individual observation, $\\hat{y}^*$, given a specific value of $x$ in general (`disp` here).  How should the 95\\% prediction interval calculated at a `disp` value of 400 compare to the corresponding 95\\% confidence interval for the mean predicted `mpg`?  Justify with a few sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Fit a simple linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our true mean predictions at various values of `disp` and make a well-labeled plot showing**\n",
    " 1. The observed values of `disp` and `mpg`.\n",
    " 2. The estimated regression line.\n",
    " 3. The upper and lower bounds of the 95% confidence interval for the true average (not the observed) `mpg` at any given displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Why do we have a confidence interval for our true mean prediction values?  Why isn't the mean prediction just a single number?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Someone asks what mean `mpg` you would predict for a `disp` value of 400. What do you tell them?  Pay attention to the confidence interval (in 1.1) above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Why does the 95% confidence interval for the mean predicted `mpg` appear to curve as we move away from the data's center?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 An alternative way to produce the confidence intervals from 1.1 is through the bootstrap though takes some care.  Create 500 bootstrap samples in order to create 500 bootstrapped regression models and store their estimated intercept and slope values.  Use these bootstrapped estimates to build the 95\\% confidence intervals as in 1.1, and recreate the plot from that question with your new bootstrapped confidence intervals.  Compare this new plot to the one from 1.1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 Another interval of uncertainty in a regression model is called a *prediction interval*.  A prediction interval gives a range of plausible values for a future individual observation, $\\hat{y}^*$, given a specific value of $x$ in general (`disp` here).  How should the 95\\% prediction interval calculated at a `disp` value of 400 compare to the corresponding 95\\% confidence interval for the mean predicted `mpg`?  Justify with a few sentences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
